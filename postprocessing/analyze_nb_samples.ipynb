{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The referee asked about the total number of samples produced by the different pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "p = psutil.Process()\n",
    "p.cpu_affinity([0])\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "jax.config.update(\"jax_disable_jit\", True)\n",
    "import arviz\n",
    "\n",
    "import h5py\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "gwosc_path = \"/home/thibeau.wouters/gw-datasets/GW190425/posterior_samples.h5\"\n",
    "jim_root_path = \"/home/thibeau.wouters/TurboPE-BNS/real_events/\"\n",
    "bilby_root_path = \"/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/\"\n",
    "paths_dict = {\"GW170817_TaylorF2\": {\"jim\": jim_root_path + \"GW170817_TaylorF2/outdir/results_production.npz\",\n",
    "                    \"bilby\": bilby_root_path + \"GW170817_TF2_with_tukey_fix_result.json\"},\n",
    "              \n",
    "              \"GW170817_NRTidalv2\": {\"jim\": jim_root_path + \"GW170817_NRTidalv2/outdir/results_production.npz\",\n",
    "                                     \"bilby\": bilby_root_path + \"GW170817_IMRPhenomD_NRTidalv2_result.json\",\n",
    "                    },\n",
    "              \n",
    "              \"GW190425_TaylorF2\": {\"jim\": jim_root_path + \"GW190425_TaylorF2/outdir_gwosc_data/results_production.npz\",\n",
    "                                    \"bilby\": bilby_root_path + \"GW190425_GWOSC_data_result.json\",\n",
    "                    },\n",
    "              \n",
    "              \"GW190425_NRTidalv2\": {\"jim\": jim_root_path + \"GW190425_NRTidalv2/outdir/results_production.npz\",\n",
    "                                     \"bilby\": bilby_root_path + \"GW190425_NRTv2_GWOSC_data_result.json\",\n",
    "                    },\n",
    "}\n",
    "\n",
    "RUN_NAMES = list(paths_dict.keys())\n",
    "JIM_VAR_NAMES = ['M_c', 'q', 's1_z', 's2_z', 'lambda_1', 'lambda_2', 'd_L', 't_c', 'phase_c', 'cos_iota', 'psi', 'ra', 'sin_dec']\n",
    "BILBY_VAR_NAMES = ['chirp_mass', 'mass_ratio', 'spin_1z', 'spin_2z', 'lambda_1', 'lambda_2', 'luminosity_distance', 'phase', 'iota', 'psi', 'ra', 'dec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ess(chains, \n",
    "                log_prob, \n",
    "                method = \"arviz\", \n",
    "                take_exp: bool = True,\n",
    "                relative: bool = False):\n",
    "    \n",
    "    # Get the weights used for inference\n",
    "    if take_exp:\n",
    "        weights = np.exp(log_prob)\n",
    "    else:\n",
    "        weights = log_prob\n",
    "    weights /= np.sum(weights) # to avoid overflow\n",
    "    weights = np.array(weights)\n",
    "    \n",
    "    if method == \"arviz\":\n",
    "        ess_list = []\n",
    "        chains = np.array(chains).T\n",
    "        for param_chains in chains:\n",
    "            ess_list.append(arviz.ess(chains))\n",
    "            \n",
    "        ess = np.mean(ess_list)\n",
    "\n",
    "    elif method == \"rejection_sampling\":\n",
    "        weights = np.exp(log_prob)\n",
    "        keep = weights > np.random.uniform(0, max(weights), weights.shape)\n",
    "        ess = np.sum(keep)\n",
    "    \n",
    "    elif method == \"kish\":\n",
    "        num = (np.sum(weights))**2\n",
    "        denom = np.sum(weights**2)\n",
    "        ess = num/denom\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Unknown method\")\n",
    "    \n",
    "    # If relative, divide by total sample size:\n",
    "    if relative:\n",
    "        ess /= len(log_prob)\n",
    "    return ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_jim_samples(path: str, \n",
    "                       report_runtime_production: bool = False,\n",
    "                       get_ess: bool = True):\n",
    "    \n",
    "    identifier = path.split(\"/\")[-3]\n",
    "    print(f\"identifier is: {identifier}\")\n",
    "    \n",
    "    data = np.load(path)\n",
    "    chains = data[\"chains\"]\n",
    "    a, b = np.shape(chains)[0], np.shape(chains)[1]\n",
    "    \n",
    "    # Also show the runtimes of the production loop\n",
    "    if report_runtime_production:\n",
    "        new_path = path.replace(\"results_production.npz\", \"runtime_production.txt\")\n",
    "        \n",
    "        time = np.loadtxt(new_path)\n",
    "        print(\"Runtime production:\", time)\n",
    "        \n",
    "    # Get the chains and the log prob\n",
    "    data = np.load(path)\n",
    "    chains = data[\"chains\"]\n",
    "    chains = np.reshape(chains, (int(a * b), 13))\n",
    "    log_prob = data[\"log_prob\"]\n",
    "    log_prob = np.reshape(log_prob, (int(a * b),))\n",
    "    \n",
    "    # DEBUG: make a histogram of log prob:\n",
    "    plt.hist(log_prob, bins=100)\n",
    "    plt.savefig(f\"./figures/hist_log_prob_{identifier}.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    print(np.shape(chains))\n",
    "    print(np.shape(log_prob))\n",
    "    \n",
    "    ess = compute_ess(chains, log_prob, method = \"kish\", relative = True)\n",
    "    \n",
    "    return a * b, ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_avg(values):\n",
    "    \"\"\"Take the average but floor and int it\"\"\"\n",
    "    \n",
    "    return int(np.floor(np.mean(list(values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identifier is: GW170817_TaylorF2\n",
      "(220000, 13)\n",
      "(220000,)\n",
      "identifier is: GW170817_NRTidalv2\n",
      "(220000, 13)\n",
      "(220000,)\n",
      "identifier is: GW190425_TaylorF2\n",
      "(600000, 13)\n",
      "(600000,)\n",
      "identifier is: GW190425_NRTidalv2\n",
      "(600000, 13)\n",
      "(600000,)\n",
      "Total samples for Jim\n",
      "{'GW170817_TaylorF2': 220000, 'GW170817_NRTidalv2': 220000, 'GW190425_TaylorF2': 600000, 'GW190425_NRTidalv2': 600000}\n",
      "ESS for Jim\n",
      "{'GW170817_TaylorF2': 6.346562498299967e-05, 'GW170817_NRTidalv2': 6.333542479671354e-05, 'GW190425_TaylorF2': 2.669603090068237e-05, 'GW190425_NRTidalv2': 2.6565362696847772e-05}\n"
     ]
    }
   ],
   "source": [
    "total_nb_samples_jim = {}\n",
    "ess_jim = {}\n",
    "\n",
    "for run_name in RUN_NAMES:\n",
    "    total, ess = get_nb_jim_samples(paths_dict[run_name][\"jim\"])\n",
    "    total_nb_samples_jim[run_name] = total\n",
    "    ess_jim[run_name] = ess\n",
    "    \n",
    "print(\"Total samples for Jim\")\n",
    "print(total_nb_samples_jim)\n",
    "\n",
    "print(\"ESS for Jim\")\n",
    "print(ess_jim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_bilby_samples(path: str):\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    posterior = data[\"posterior\"][\"content\"]\n",
    "    mc = posterior[\"chirp_mass\"] # just taking the chirp mass samples as an example\n",
    "    n = len(mc)\n",
    "    \n",
    "    log_likelihood = np.array(posterior[\"log_likelihood\"])\n",
    "    print(f\"log_likelihood: {log_likelihood}\")\n",
    "    \n",
    "    nested_samples = data[\"nested_samples\"]['content'] # dict with keys: 'dec', 'ra', 'chirp_mass', 'mass_ratio', 'chi_1', 'chi_2', 'luminosity_distance', 'cos_theta_jn', 'psi', 'phase', 'lambda_1', 'lambda_2', 'geocent_time', 'weights', 'log_likelihood'\n",
    "    nested_samples_weights = nested_samples[\"weights\"]\n",
    "    samples = data[\"samples\"]['content']\n",
    "    \n",
    "    print(f\"Nested samples and samples shape: {np.shape(nested_samples_weights)}, {np.shape(samples)[0]}\")\n",
    "    print(f\"nested_samples_weights min and max: {np.min(nested_samples_weights)}, {np.max(nested_samples_weights)}\")\n",
    "    \n",
    "    avg_ess = compute_ess(samples, nested_samples_weights, take_exp = False, method = \"kish\", relative = True)\n",
    "    # avg_ess = compute_ess(samples, log_likelihood, take_exp = True, method = \"arviz\", relative = True)\n",
    "        \n",
    "    return n, avg_ess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pBilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_likelihood: [547.00313918 548.69856653 549.43301019 ... 569.99966648 569.99966648\n",
      " 569.99966648]\n",
      "Nested samples and samples shape: (44782,), 44782\n",
      "nested_samples_weights min and max: 0.0, 0.00016014352358832842\n",
      "log_likelihood: [539.12220195 540.08677565 540.63059469 ... 561.13490206 561.13490206\n",
      " 561.13490206]\n",
      "Nested samples and samples shape: (45365,), 45365\n",
      "nested_samples_weights min and max: 0.0, 0.00015848338278036988\n",
      "log_likelihood: [65.05886983 66.21304446 66.81574675 ... 86.80823552 86.80823552\n",
      " 86.80823552]\n",
      "Nested samples and samples shape: (30782,), 30782\n",
      "nested_samples_weights min and max: 0.0, 0.00014868191631388282\n",
      "log_likelihood: [64.81474159 65.86292189 66.34509702 ... 85.93556712 85.93556712\n",
      " 85.93556712]\n",
      "Nested samples and samples shape: (30277,), 30277\n",
      "nested_samples_weights min and max: 0.0, 0.00014336516234732138\n",
      "Total samples for Bilby\n",
      "{'GW170817_TaylorF2': 44782, 'GW170817_NRTidalv2': 45365, 'GW190425_TaylorF2': 30782, 'GW190425_NRTidalv2': 30277}\n",
      "Average total samples for Bilby\n",
      "37801\n",
      "ESS for Bilby\n",
      "{'GW170817_TaylorF2': 0.00030568027253872327, 'GW170817_NRTidalv2': 0.00030137565976957984, 'GW190425_TaylorF2': 0.0004869997561521324, 'GW190425_NRTidalv2': 0.0004965113358296233}\n",
      "Average ESS for Bilby\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "total_nb_samples_bilby = {}\n",
    "ess_bilby = {}\n",
    "\n",
    "for run_name in RUN_NAMES:\n",
    "    path = paths_dict[run_name][\"bilby\"]\n",
    "    total, ess = get_nb_bilby_samples(path)\n",
    "    \n",
    "    total_nb_samples_bilby[run_name] = total\n",
    "    ess_bilby[run_name] = ess\n",
    "    \n",
    "print(\"Total samples for Bilby\")\n",
    "print(total_nb_samples_bilby)\n",
    "\n",
    "print(\"Average total samples for Bilby\")\n",
    "avg_total_nb_samples_bilby = my_avg(list(total_nb_samples_bilby.values()))\n",
    "print(avg_total_nb_samples_bilby)\n",
    "\n",
    "print(\"ESS for Bilby\")\n",
    "print(ess_bilby)\n",
    "\n",
    "avg_ess_bilby = my_avg(list(ess_bilby.values()))\n",
    "print(\"Average ESS for Bilby\")\n",
    "print(avg_ess_bilby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative binning-Bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nb_rb_bilby_samples(path: str):\n",
    "    \n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        posterior = f[\"posterior\"]\n",
    "        mc = posterior[\"chirp_mass\"][()] # just taking the chirp mass samples as an example\n",
    "        n = len(mc)\n",
    "        \n",
    "        my_ess_list = []\n",
    "        for name in BILBY_VAR_NAMES:\n",
    "            values = posterior[name][()]\n",
    "            \n",
    "            # NOTE: sometimes the json is broken and there are dicts instead of floats\n",
    "            if isinstance(values[0], dict):\n",
    "                new_values = [item['content'] for item in values]\n",
    "                values = new_values\n",
    "\n",
    "            values = np.array(values)\n",
    "\n",
    "            ess = arviz.ess(values)\n",
    "            # print(f\"ESS for {name} production: {ess}\")\n",
    "            my_ess_list.append(ess)\n",
    "                \n",
    "        avg_ess = int(np.floor(np.mean(my_ess_list)))\n",
    "    \n",
    "    return n, avg_ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW170817_TaylorF2\n",
      "GW170817_NRTidalv2\n",
      "GW190425_TaylorF2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GW190425_NRTidalv2\n",
      "Total samples for RB Bilby\n",
      "{'GW170817_TaylorF2': 5258, 'GW170817_NRTidalv2': 5172, 'GW190425_TaylorF2': 6743, 'GW190425_NRTidalv2': 5172}\n",
      "Average total samples for RB Bilby\n",
      "5586\n",
      "ESS for RB Bilby\n",
      "{'GW170817_TaylorF2': 3274, 'GW170817_NRTidalv2': 3837, 'GW190425_TaylorF2': 3661, 'GW190425_NRTidalv2': 3837}\n",
      "Average ESS for RB Bilby\n",
      "3652\n"
     ]
    }
   ],
   "source": [
    "rb_paths = [\"../RB/gw170817_relbin_TaylorF2_result.hdf5\", \n",
    "            \"../RB/gw170817_relbin_result.hdf5\",\n",
    "            \"../RB/gw190425_relbin_TaylorF2_result.hdf5\",\n",
    "            \"../RB/gw190425_relbin_result.hdf5\"]\n",
    "\n",
    "total_nb_samples_rb_bilby = {}\n",
    "ess_rb_bilby = {}\n",
    "\n",
    "for path, run_name in zip(rb_paths, RUN_NAMES):\n",
    "    print(run_name)\n",
    "    total, ess = get_nb_rb_bilby_samples(path)\n",
    "\n",
    "    total_nb_samples_rb_bilby[run_name] = total\n",
    "    ess_rb_bilby[run_name] = ess\n",
    "    \n",
    "print(\"Total samples for RB Bilby\")\n",
    "print(total_nb_samples_rb_bilby)\n",
    "\n",
    "print(\"Average total samples for RB Bilby\")\n",
    "avg_total_nb_samples_rb_bilby = my_avg(list(total_nb_samples_rb_bilby.values()))\n",
    "print(avg_total_nb_samples_rb_bilby)\n",
    "\n",
    "print(\"ESS for RB Bilby\")\n",
    "print(ess_rb_bilby)\n",
    "\n",
    "avg_ess_rb_bilby = my_avg(list(ess_rb_bilby.values()))\n",
    "print(\"Average ESS for RB Bilby\")\n",
    "print(avg_ess_rb_bilby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROQ-Bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thibeau.wouters/TurboPE-BNS/ROQ/gw170817_ROQ_result.hdf5\n",
      "/home/thibeau.wouters/TurboPE-BNS/ROQ/gw190425_ROQ_result.hdf5\n",
      "Total samples for ROQ Bilby\n",
      "{'/home/thibeau.wouters/TurboPE-BNS/ROQ/gw170817_ROQ_result.hdf5': 5258, '/home/thibeau.wouters/TurboPE-BNS/ROQ/gw190425_ROQ_result.hdf5': 5172}\n",
      "Average total samples for ROQ Bilby\n",
      "5215\n",
      "ESS for ROQ Bilby\n",
      "{'/home/thibeau.wouters/TurboPE-BNS/ROQ/gw170817_ROQ_result.hdf5': 3274, '/home/thibeau.wouters/TurboPE-BNS/ROQ/gw190425_ROQ_result.hdf5': 3837}\n",
      "Average ESS for ROQ Bilby\n",
      "3555\n"
     ]
    }
   ],
   "source": [
    "roq_paths = [\"/home/thibeau.wouters/TurboPE-BNS/ROQ/gw170817_ROQ_result.hdf5\",\n",
    "             \"/home/thibeau.wouters/TurboPE-BNS/ROQ/gw190425_ROQ_result.hdf5\"]\n",
    "\n",
    "total_nb_samples_roq_bilby = {}\n",
    "ess_roq_bilby = {}\n",
    "\n",
    "for path, run_name in zip(rb_paths, roq_paths):\n",
    "    print(run_name)\n",
    "    total, ess = get_nb_rb_bilby_samples(path)\n",
    "\n",
    "    total_nb_samples_roq_bilby[run_name] = total\n",
    "    ess_roq_bilby[run_name] = ess\n",
    "    \n",
    "print(\"Total samples for ROQ Bilby\")\n",
    "print(total_nb_samples_roq_bilby)\n",
    "\n",
    "print(\"Average total samples for ROQ Bilby\")\n",
    "avg_total_nb_samples_roq_bilby = my_avg(list(total_nb_samples_roq_bilby.values()))\n",
    "print(avg_total_nb_samples_roq_bilby)\n",
    "\n",
    "print(\"ESS for ROQ Bilby\")\n",
    "print(ess_roq_bilby)\n",
    "\n",
    "avg_ess_roq_bilby = my_avg(list(ess_roq_bilby.values()))\n",
    "print(\"Average ESS for ROQ Bilby\")\n",
    "print(avg_ess_roq_bilby)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220000, 600000)\n",
      "(0.0709587168064469, 0.12169029575884786)\n"
     ]
    }
   ],
   "source": [
    "values = list(total_nb_samples_jim.values())\n",
    "print((np.min(values), np.max(values)))\n",
    "\n",
    "values = list(ess_jim.values())\n",
    "print((np.min(values), np.max(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_get_number(value):\n",
    "    value = int(np.round(value))\n",
    "    my_string = str(value)\n",
    "    first, second = my_string[0], my_string[1]\n",
    "    \n",
    "    power = int(np.floor(np.log10(value)))\n",
    "    \n",
    "    return_string = r\"{}.{} \\times 10^{}\".format(first, second, power)\n",
    "    \n",
    "    return return_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[310], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m latex_code \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m& Number of samples & Number of effective samples \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mhline\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtextsc\u001b[39m\u001b[39m{{\u001b[39m\u001b[39mJim}} & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtextsc\u001b[39m\u001b[39m{{\u001b[39m\u001b[39mpBilby}} & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtextsc\u001b[39m\u001b[39m{{\u001b[39m\u001b[39mRB-Bilby}} & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtextsc\u001b[39m\u001b[39m{{\u001b[39m\u001b[39mROQ-Bilby}} & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ & $\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m$ \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\\\\\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mhline\u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[1;32m      2\u001b[0m \u001b[39m.\u001b[39mformat(my_get_number(np\u001b[39m.\u001b[39mmean(\u001b[39mlist\u001b[39m(total_nb_samples_jim\u001b[39m.\u001b[39mvalues()))),\n\u001b[0;32m----> 3\u001b[0m         my_get_number(np\u001b[39m.\u001b[39;49mmean(\u001b[39mlist\u001b[39;49m(ess_jim\u001b[39m.\u001b[39;49mvalues()))),\n\u001b[1;32m      4\u001b[0m         my_get_number(avg_total_nb_samples_bilby),\n\u001b[1;32m      5\u001b[0m         my_get_number(avg_ess_bilby),\n\u001b[1;32m      6\u001b[0m         my_get_number(avg_total_nb_samples_rb_bilby),\n\u001b[1;32m      7\u001b[0m         my_get_number(avg_ess_rb_bilby),\n\u001b[1;32m      8\u001b[0m         my_get_number(avg_total_nb_samples_roq_bilby),\n\u001b[1;32m      9\u001b[0m         my_get_number(avg_ess_roq_bilby)\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(latex_code)\n\u001b[1;32m     14\u001b[0m \u001b[39m# my_get_number(np.min(list(total_nb_samples_jim.values()))) + \" -- \" + my_get_number(np.max(list(total_nb_samples_jim.values()))),\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m# my_get_number(np.min(list(ess_jim.values()))) + \" -- \" + my_get_number(np.max(list(ess_jim.values())))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[309], line 4\u001b[0m, in \u001b[0;36mmy_get_number\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m      2\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mround(value))\n\u001b[1;32m      3\u001b[0m my_string \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(value)\n\u001b[0;32m----> 4\u001b[0m first, second \u001b[39m=\u001b[39m my_string[\u001b[39m0\u001b[39m], my_string[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m      6\u001b[0m power \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(np\u001b[39m.\u001b[39mfloor(np\u001b[39m.\u001b[39mlog10(value)))\n\u001b[1;32m      8\u001b[0m return_string \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtimes 10^\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(first, second, power)\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "latex_code = '& Number of samples & Number of effective samples \\\\\\\\\\n \\hline\\\\hline\\n \\\\textsc{{Jim}} & ${}$ & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{pBilby}} & ${}$ & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{RB-Bilby}} & ${}$ & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{ROQ-Bilby}} & ${}$ & ${}$ \\\\\\\\ \\\\hline\\\\hline'\\\n",
    ".format(my_get_number(np.mean(list(total_nb_samples_jim.values()))),\n",
    "        my_get_number(np.mean(list(ess_jim.values()))),\n",
    "        my_get_number(avg_total_nb_samples_bilby),\n",
    "        my_get_number(avg_ess_bilby),\n",
    "        my_get_number(avg_total_nb_samples_rb_bilby),\n",
    "        my_get_number(avg_ess_rb_bilby),\n",
    "        my_get_number(avg_total_nb_samples_roq_bilby),\n",
    "        my_get_number(avg_ess_roq_bilby)\n",
    ")\n",
    "\n",
    "print(latex_code)\n",
    "\n",
    "# my_get_number(np.min(list(total_nb_samples_jim.values()))) + \" -- \" + my_get_number(np.max(list(total_nb_samples_jim.values()))),\n",
    "# my_get_number(np.min(list(ess_jim.values()))) + \" -- \" + my_get_number(np.max(list(ess_jim.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only quote ESS to make it more informed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& Number of effective samples \\\\\n",
      " \\hline\\hline\n",
      " \\textsc{Jim} & $5.2 \\times 10^3$ \\\\ \\hline \n",
      " \\textsc{pBilby} & $4.5 \\times 10^3$ \\\\ \\hline \n",
      " \\textsc{RB-Bilby} & $3.6 \\times 10^3$ \\\\ \\hline \n",
      " \\textsc{ROQ-Bilby} & $3.5 \\times 10^3$ \\\\ \\hline\\hline\n"
     ]
    }
   ],
   "source": [
    "latex_code = '& Number of effective samples \\\\\\\\\\n \\hline\\\\hline\\n \\\\textsc{{Jim}} & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{pBilby}} & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{RB-Bilby}} & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{ROQ-Bilby}} & ${}$ \\\\\\\\ \\\\hline\\\\hline'\\\n",
    ".format(my_get_number(np.mean(list(ess_jim.values()))),\n",
    "        my_get_number(avg_ess_bilby),\n",
    "        my_get_number(avg_ess_rb_bilby),\n",
    "        my_get_number(avg_ess_roq_bilby)\n",
    ")\n",
    "\n",
    "print(latex_code)\n",
    "\n",
    "# my_get_number(np.min(list(total_nb_samples_jim.values()))) + \" -- \" + my_get_number(np.max(list(total_nb_samples_jim.values()))),\n",
    "# my_get_number(np.min(list(ess_jim.values()))) + \" -- \" + my_get_number(np.max(list(ess_jim.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
