{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the runtimes of the injections we did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "p = psutil.Process()\n",
    "p.cpu_affinity([0])\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import json\n",
    "import h5py\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Latex\n",
    "\n",
    "params = {\"axes.grid\": True,\n",
    "        \"text.usetex\" : True,\n",
    "        \"font.family\" : \"serif\",\n",
    "        \"ytick.color\" : \"black\",\n",
    "        \"xtick.color\" : \"black\",\n",
    "        \"axes.labelcolor\" : \"black\",\n",
    "        \"axes.edgecolor\" : \"black\",\n",
    "        \"font.serif\" : [\"Computer Modern Serif\"],\n",
    "        \"xtick.labelsize\": 16,\n",
    "        \"ytick.labelsize\": 16,\n",
    "        \"axes.labelsize\": 16,\n",
    "        \"legend.fontsize\": 16,\n",
    "        \"legend.title_fontsize\": 16,\n",
    "        \"figure.titlesize\": 16}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "import copy\n",
    "\n",
    "import utils_compare_runs as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdirs_injections = {\"TF2\": \"../injections/outdir_TF2/\",\n",
    "                      \"NRTv2\": \"../injections/outdir_NRTv2/\"}\n",
    "\n",
    "jim_root_path = \"/home/thibeau.wouters/TurboPE-BNS/real_events/\"\n",
    "jim_root_path_no_taper = \"/home/thibeau.wouters/TurboPE-BNS/real_events_no_taper/\"\n",
    "bilby_root_path = \"/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/\"\n",
    "paths_dict = {\"GW170817_TaylorF2\": {\"jim\": jim_root_path + \"GW170817_TaylorF2/outdir_snellius/\",\n",
    "                    \"bilby\": bilby_root_path + \"GW170817_TF2_with_tukey_fix_result.json\"},\n",
    "              \n",
    "              \"GW170817_NRTidalv2\": {\"jim\": jim_root_path_no_taper + \"GW170817_NRTidalv2/outdir_snellius/\",\n",
    "                                     \"bilby\": bilby_root_path + \"GW170817_IMRPhenomD_NRTidalv2_result.json\",\n",
    "                    },\n",
    "              \n",
    "              \"GW190425_TaylorF2\": {\"jim\": jim_root_path + \"GW190425_TaylorF2/outdir_snellius/\",\n",
    "                                    \"bilby\": bilby_root_path + \"GW190425_GWOSC_data_result.json\",\n",
    "                    },\n",
    "              \"GW190425_NRTidalv2\": {\"jim\": jim_root_path_no_taper + \"GW190425_NRTidalv2/outdir_snellius/\",\n",
    "                                     \"bilby\": bilby_root_path + \"GW190425_NRTv2_GWOSC_data_result.json\",\n",
    "                    }, # NOTE: even though the PE samples are taken from the original path, the timing run is under \"no_taper\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_runtime(runtime_minutes: float, \n",
    "                   nb_round: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Simple function to format the runtime in minutes appropriately.\n",
    "\n",
    "    Args:\n",
    "        runtime_minutes (float): Runtime in minutes\n",
    "        nb_round (int, optional): Number of digits for rounding. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        str: Nicely formatted runtime\n",
    "    \"\"\"\n",
    "    runtime_string = str(np.round(runtime_minutes, nb_round))\n",
    "    before, after = runtime_string.split(\".\")\n",
    "    if len(after) == 1:\n",
    "        runtime_string = before + \".\" + after + \"0\" \n",
    "        \n",
    "    if len(runtime_string) == 4:\n",
    "        runtime_string = \"\\\\phantom{0}\" + runtime_string\n",
    "        \n",
    "    return runtime_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_runtime_injection(run_dir: str,\n",
    "                            nb_round: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Fetch the runtime of a given run directory of a jim run.\n",
    "\n",
    "    Args:\n",
    "        run_dir (str): Directory of the run, i.e. the outdir\n",
    "\n",
    "    Returns:\n",
    "        float: Runtime.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch runtimes of the individual parts:\n",
    "    with open(run_dir + \"/runtime.txt\", \"r\") as f:\n",
    "        runtime_seconds = float(f.read())\n",
    "        \n",
    "    runtime_minutes = runtime_seconds / 60\n",
    "    runtime_string = format_runtime(runtime_minutes, nb_round)\n",
    "            \n",
    "    return runtime_seconds, runtime_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_runtime_event(run_dir: str,\n",
    "                        nb_round: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Fetch the runtime of a given run directory of a jim run.\n",
    "\n",
    "    Args:\n",
    "        run_dir (str): Directory of the run, i.e. the outdir\n",
    "\n",
    "    Returns:\n",
    "        float: Runtime.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fetch the complete wall-time: this includes everything! Including JIT compilation etc\n",
    "    with open(run_dir + \"/runtime.txt\", \"r\") as f:\n",
    "        runtime_seconds = float(f.read())\n",
    "     \n",
    "    # # TODO: check whether this was correct by looking at the slurm out files   \n",
    "    # # Note: the reruns were done with 1000 loops for evosax, but the fixed ref params used 2000 loops, so adding that once more\n",
    "    # with open(run_dir + \"/runtime_evosax.txt\", \"r\") as f:\n",
    "    #     runtime_seconds -= float(f.read())\n",
    "        \n",
    "    runtime_minutes = runtime_seconds / 60\n",
    "    runtime_string = format_runtime(runtime_minutes, nb_round)\n",
    "            \n",
    "    return runtime_seconds, runtime_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_runtime_evosax_event(run_dir: str,\n",
    "                               nb_round: int = 2) -> float:\n",
    "    \"\"\"\n",
    "    Fetch the runtime of a given real event run spent only on the evosax (computing reference parameters).\n",
    "\n",
    "    Args:\n",
    "        run_dir (str): Directory of the run, i.e. the outdir\n",
    "\n",
    "    Returns:\n",
    "        float: Runtime.\n",
    "    \"\"\"\n",
    "    \n",
    "    # if \"GW170817_NRTidalv2\" in run_dir or \"GW170817_TaylorF2\" in run_dir:\n",
    "    #     multiplier = 1\n",
    "    # else:\n",
    "    #     multiplier = 2\n",
    "    \n",
    "    # # Note: the reruns were done with 1000 loops for evosax, but the fixed ref params used 2000 loops, so adding that once more\n",
    "    # # NOTE: this is not true for GW170817_NRTidalv2 and GW170817_TaylorF2 sorrry that this is such a mess jesus christ\n",
    "    # # Also, for GW190425 NRTidalv2, the evosax with the rerun for the referee was skipped\n",
    "    # # Check the slurm.out files for the correct runtimes in case of doubt\n",
    "    # if \"GW190425_NRTidalv2\" in run_dir:\n",
    "    #     runtime_seconds = 6.15 * 60\n",
    "    # else:\n",
    "    with open(run_dir + \"/runtime_evosax.txt\", \"r\") as f:\n",
    "        runtime_seconds = float(f.read())\n",
    "            \n",
    "    runtime_minutes = runtime_seconds / 60\n",
    "    runtime_string = format_runtime(runtime_minutes, nb_round)\n",
    "            \n",
    "    return runtime_seconds, runtime_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_runtime_bilby(event_name: str, \n",
    "                        nb_round: int = 2,\n",
    "                        convert_to_hours: bool = True) -> tuple[float, str]:\n",
    "    \"\"\"\n",
    "    Fetch and format the runtime of analyzing one of the real events for bilby. \n",
    "\n",
    "    Args:\n",
    "        event_name (str): Identifier of the event, format GW_WF, e.g. GW170817_TaylorF2\n",
    "        outdir_name (str): Name of the outdir, e.g. `outdir`\n",
    "        runtime_filename (str, optional): _description_. Defaults to \"runtime.txt\".\n",
    "        nb_round (int, optional): _description_. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Tuple of float value, being the runtime in seconds, and a string with the runtime in minutes\n",
    "    \"\"\"\n",
    "    \n",
    "    path = paths_dict[event_name][\"bilby\"]\n",
    "    print(f\"Bilby path: {path}\")\n",
    "    with open(path, \"r\") as f:\n",
    "        bilby_data = json.load(f)\n",
    "        runtime_seconds = float(bilby_data[\"sampling_time\"])\n",
    "        \n",
    "        nlive = float(bilby_data[\"meta_data\"][\"command_line_args\"][\"nlive\"])\n",
    "        print(f\"event_name: {event_name} nlive: {nlive}\")\n",
    "        \n",
    "    runtime_minutes = runtime_seconds / 60\n",
    "    if convert_to_hours:\n",
    "        runtime_minutes /= 60 # TODO fix the naming, or not, if I am too lazy in the end\n",
    "    runtime_string = format_runtime(runtime_minutes, nb_round)\n",
    "    \n",
    "    return runtime_seconds, runtime_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injections runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping ../injections/outdir_TF2/injection_54, error: [Errno 2] No such file or directory: '../injections/outdir_TF2/injection_54/runtime.txt'\n"
     ]
    }
   ],
   "source": [
    "runtimes_dict = {} \n",
    "\n",
    "for name in outdirs_injections.keys():\n",
    "    outdir = outdirs_injections[name]\n",
    "    runtimes = []\n",
    "    for subdir in os.listdir(outdir):\n",
    "        rundir = outdir + subdir\n",
    "        runtime_path = rundir + \"/runtime.txt\"\n",
    "        \n",
    "        try:\n",
    "            runtime, _ = fetch_runtime_injection(rundir)\n",
    "            runtimes.append(runtime)\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {rundir}, error: {e}\")\n",
    "            \n",
    "    runtimes_dict[name] = np.array(runtimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes = True # whether to convert runtimes to minutes rather than seconds\n",
    "\n",
    "if minutes:\n",
    "    denominator = 60\n",
    "else:\n",
    "    denominator = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a histogram of the runtimes, more as a sanity check for myself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_TF2, edges = np.histogram(runtimes_dict[\"TF2\"] / denominator, bins = 20, density = True)\n",
    "# hist_NRTv2, _ = np.histogram(runtimes_dict[\"NRTv2\"] / denominator, bins = edges, density = True)\n",
    "\n",
    "# if minutes:\n",
    "#     xlabel = \"Runtime (min)\"\n",
    "# else:\n",
    "#     xlabel = \"Runtime (s)\"\n",
    "\n",
    "# stairs_kwargs = {\"linewidth\": 2}\n",
    "\n",
    "# # Create the figure\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.stairs(hist_TF2, edges, label = \"TF2\", **stairs_kwargs)\n",
    "# plt.stairs(hist_NRTv2, edges, label = \"NRTv2\", **stairs_kwargs)\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel(xlabel)\n",
    "# plt.ylabel(\"Density\")\n",
    "# # plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtimes for compilation and initializing the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation: mean +/- std: 2.59 +/- 0.33 minutes\n"
     ]
    }
   ],
   "source": [
    "runtimes_compilation_filename = \"../data/runtimes_compilation.txt\"\n",
    "runtimes_compilation = np.loadtxt(runtimes_compilation_filename, delimiter=\",\")\n",
    "\n",
    "compilation_mean, compilation_std = np.mean(runtimes_compilation), np.std(runtimes_compilation)\n",
    "print(f\"Compilation: mean +/- std: {compilation_mean / 60:.2f} +/- {compilation_std / 60:.2f} minutes\")\n",
    "\n",
    "compilation_mean_minutes = compilation_mean / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can subtract the time for compiling etc, if wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean and std for TF2\n",
      "$(27.09 \\pm 12.18)$ min\n",
      "Median for TF2\n",
      "24.758970030148824\n",
      "$24.76$ min\n",
      "Mean and std for NRTv2\n",
      "$(21.10 \\pm \\phantom{0}9.16)$ min\n",
      "Median for NRTv2\n",
      "18.02008366982142\n",
      "$18.02$ min\n"
     ]
    }
   ],
   "source": [
    "jim_runtimes_injections_float = {} # in seconds\n",
    "jim_runtimes_injections = {}\n",
    "jim_runtimes_injections_median = {}\n",
    "jim_runtimes_injections_median_str = {}\n",
    "subtract_number = compilation_mean_minutes # in case we want to extract the compilation time for reporting in the paper\n",
    "subtract_number = 0 # in case we DO NOT want to extract the compilation time for reporting in the paper\n",
    "\n",
    "jim_total_runtime_injections = 0\n",
    "\n",
    "for name, runtimes in runtimes_dict.items():\n",
    "    \n",
    "    # subtract compilation time in seconds\n",
    "    jim_total_runtime_injections += np.sum(runtimes - subtract_number * 60)\n",
    "    \n",
    "    ### Mean +/- std:\n",
    "    mean_str = format_runtime(np.mean(runtimes / denominator) - subtract_number)\n",
    "    std_str = format_runtime(np.std(runtimes / denominator))\n",
    "    median_value = np.median(runtimes / denominator) - subtract_number\n",
    "    median_str = format_runtime(median_value)\n",
    "    \n",
    "    jim_runtimes_injections_float[name] = np.mean(runtimes) # in seconds\n",
    "    jim_runtime_str = r\"$({} \\pm {})$ min\".format(mean_str, std_str)\n",
    "    print(f\"Mean and std for {name}\")\n",
    "    print(jim_runtime_str)\n",
    "    jim_runtimes_injections[name] = jim_runtime_str\n",
    "    \n",
    "    ### Median:\n",
    "    median_str = r\"${}$ min\".format(median_str)\n",
    "    \n",
    "    jim_runtimes_injections_median[name] = median_value\n",
    "    jim_runtimes_injections_median_str[name] = median_str\n",
    "    \n",
    "    # Print\n",
    "    print(f\"Median for {name}\")\n",
    "    print(median_value)\n",
    "    print(median_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch jim runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GW170817_TaylorF2', 'GW170817_NRTidalv2', 'GW190425_TaylorF2', 'GW190425_NRTidalv2']\n",
      "GW170817_TaylorF2\n",
      "Fetching runtimes from run: /home/thibeau.wouters/TurboPE-BNS/real_events/GW170817_TaylorF2/outdir_snellius/\n",
      "1211.0\n",
      "291.2467391490936\n",
      "GW170817_NRTidalv2\n",
      "Fetching runtimes from run: /home/thibeau.wouters/TurboPE-BNS/real_events_no_taper/GW170817_NRTidalv2/outdir_snellius/\n",
      "1858.2805058956146\n",
      "323.01397371292114\n",
      "GW190425_TaylorF2\n",
      "Fetching runtimes from run: /home/thibeau.wouters/TurboPE-BNS/real_events/GW190425_TaylorF2/outdir_snellius/\n",
      "1256.2541539669037\n",
      "158.08987164497375\n",
      "GW190425_NRTidalv2\n",
      "Fetching runtimes from run: /home/thibeau.wouters/TurboPE-BNS/real_events_no_taper/GW190425_NRTidalv2/outdir_snellius/\n",
      "1467.5056896209717\n",
      "195.74333667755127\n"
     ]
    }
   ],
   "source": [
    "run_names = list(paths_dict.keys())\n",
    "print(run_names)\n",
    "\n",
    "jim_runtimes_float = {}\n",
    "jim_runtimes_str = {}\n",
    "\n",
    "jim_runtimes_float_evosax = {}\n",
    "jim_runtimes_str_evosax = {}\n",
    "\n",
    "jim_runtimes_float_sampling = {} # total runtime - evosax time\n",
    "jim_runtimes_str_sampling = {}\n",
    "\n",
    "\n",
    "for run in run_names:\n",
    "    print(run)\n",
    "    path = paths_dict[run][\"jim\"]\n",
    "    path = path.replace(\"/outdir/\", \"/outdir_snellius/\")\n",
    "    print(f\"Fetching runtimes from run: {path}\")\n",
    "    runtime_float, runtime_str = fetch_runtime_event(path)\n",
    "    runtime_float_evosax, runtime_str_evosax = fetch_runtime_evosax_event(path)\n",
    "    print(runtime_float)\n",
    "    print(runtime_float_evosax)\n",
    "    \n",
    "    runtime_float_sampling = runtime_float - runtime_float_evosax\n",
    "    runtime_str_sampling = format_runtime(runtime_float_sampling / 60)\n",
    "    \n",
    "    # Overall runtime\n",
    "    jim_runtimes_float[run] = runtime_float\n",
    "    jim_runtimes_str[run] = runtime_str\n",
    "    \n",
    "    # Runtime for evosax\n",
    "    jim_runtimes_float_evosax[run] = runtime_float_evosax\n",
    "    jim_runtimes_str_evosax[run] = runtime_str_evosax\n",
    "    \n",
    "    # Runtime for total - evosax\n",
    "    jim_runtimes_float_sampling[run] = runtime_float_sampling\n",
    "    jim_runtimes_str_sampling[run] = runtime_str_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch pbilby runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the numbers that Peter gave me:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Override with the numbers obtained from the log file of the runs instead:\n",
    "# bilby_runtimes_total = {}\n",
    "# bilby_runtimes_total[\"GW170817_TaylorF2\"]  = 0.0\n",
    "# bilby_runtimes_total[\"GW170817_NRTidalv2\"] = 12 * (60) ** 2 + 34 * 60 + 15\n",
    "# bilby_runtimes_total[\"GW190425_TaylorF2\"]  = 0.0\n",
    "# bilby_runtimes_total[\"GW190425_NRTidalv2\"] =  5 * (60) ** 2 + 39 * 60 + 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW170817_TF2_with_tukey_fix_result.json\n",
      "Bilby path: /home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW170817_TF2_with_tukey_fix_result.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event_name: GW170817_TaylorF2 nlive: 1024.0\n",
      "/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW170817_IMRPhenomD_NRTidalv2_result.json\n",
      "Bilby path: /home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW170817_IMRPhenomD_NRTidalv2_result.json\n",
      "event_name: GW170817_NRTidalv2 nlive: 1024.0\n",
      "/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW190425_GWOSC_data_result.json\n",
      "Bilby path: /home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW190425_GWOSC_data_result.json\n",
      "event_name: GW190425_TaylorF2 nlive: 1024.0\n",
      "/home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW190425_NRTv2_GWOSC_data_result.json\n",
      "Bilby path: /home/thibeau.wouters/jim_pbilby_samples/older_bilby_version/GW190425_NRTv2_GWOSC_data_result.json\n",
      "event_name: GW190425_NRTidalv2 nlive: 1024.0\n"
     ]
    }
   ],
   "source": [
    "bilby_runtimes_float = {}\n",
    "bilby_runtimes_str = {}\n",
    "for run in run_names:\n",
    "    path = paths_dict[run][\"bilby\"]\n",
    "    print(path)\n",
    "    runtime_float, runtime_string = fetch_runtime_bilby(run, convert_to_hours=True)\n",
    "        \n",
    "    bilby_runtimes_float[run] = runtime_float\n",
    "    bilby_runtimes_str[run] = runtime_string\n",
    "    \n",
    "bilby_runtimes_total = bilby_runtimes_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dollar signs and minute string\n",
    "for key, value in jim_runtimes_str.items():\n",
    "    jim_runtimes_str[key] = f\"${value}$ min\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert list(jim_runtimes_float.keys()) == list(bilby_runtimes_float.keys())\n",
    "assert list(jim_runtimes_str.keys()) == list(bilby_runtimes_str.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put hours in the formatting for pbilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in bilby_runtimes_str.items():\n",
    "    bilby_runtimes_str[key] = f\"${value}$ h\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROQ sampling times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bilby_runtime(path: str) -> float:\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        runtime = f[\"sampling_time\"][()]\n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The setup of the runs is on Potsdam: `/home/enlil/ppang/Projects/runs_for_Colm/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time for ROQ GW170817: 1.647744848611111 hours\n",
      "Sampling time for ROQ GW190425: 0.9662301444444444 hours\n",
      "Average sampling time for ROQ GW190425: 1.306987496527778 hours\n"
     ]
    }
   ],
   "source": [
    "roq_sampling_time_GW170817 = read_bilby_runtime(utils.bilby_ROQ_paths_dict[\"GW170817_NRTidalv2\"])\n",
    "roq_sampling_time_GW190425 = read_bilby_runtime(utils.bilby_ROQ_paths_dict[\"GW190425_NRTidalv2\"])\n",
    "\n",
    "print(f\"Sampling time for ROQ GW170817: {roq_sampling_time_GW170817 / 3600} hours\")\n",
    "print(f\"Sampling time for ROQ GW190425: {roq_sampling_time_GW190425 / 3600} hours\")\n",
    "\n",
    "avg_runtime_roq = (roq_sampling_time_GW170817 + roq_sampling_time_GW190425) / 2\n",
    "print(f\"Average sampling time for ROQ GW190425: {avg_runtime_roq / 3600} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative binning with bilby runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling time for RB GW170817 TaylorF2: 3.798958034722164 hours\n",
      "Sampling time for RB GW170817 NRTidalv2: 4.114050004444461 hours\n",
      "Sampling time for RB GW190425 TaylorF2: 2.8113986983334 hours\n",
      "Sampling time for RB GW190425 NRTidalv2: 2.415969105555442 hours\n",
      "Average sampling time for RB: 3.2850939607638665 hours\n"
     ]
    }
   ],
   "source": [
    "relbin_sampling_time_GW170817_TaylorF2 = read_bilby_runtime(utils.bilby_RB_paths_dict[\"GW170817_TaylorF2\"])\n",
    "relbin_sampling_time_GW170817_NRTidalv2 = read_bilby_runtime(utils.bilby_RB_paths_dict[\"GW170817_NRTidalv2\"])\n",
    "relbin_sampling_time_GW190425_TaylorF2 = read_bilby_runtime(utils.bilby_RB_paths_dict[\"GW190425_TaylorF2\"])\n",
    "relbin_sampling_time_GW190425_NRTidalv2 = read_bilby_runtime(utils.bilby_RB_paths_dict[\"GW190425_NRTidalv2\"])\n",
    "\n",
    "print(f\"Sampling time for RB GW170817 TaylorF2: {relbin_sampling_time_GW170817_TaylorF2 / 3600} hours\")\n",
    "print(f\"Sampling time for RB GW170817 NRTidalv2: {relbin_sampling_time_GW170817_NRTidalv2 / 3600} hours\")\n",
    "print(f\"Sampling time for RB GW190425 TaylorF2: {relbin_sampling_time_GW190425_TaylorF2 / 3600} hours\")\n",
    "print(f\"Sampling time for RB GW190425 NRTidalv2: {relbin_sampling_time_GW190425_NRTidalv2 / 3600} hours\")\n",
    "\n",
    "avg_runtime_relbin = (relbin_sampling_time_GW170817_TaylorF2 + relbin_sampling_time_GW190425_TaylorF2 + relbin_sampling_time_GW170817_NRTidalv2 + relbin_sampling_time_GW190425_NRTidalv2) / 4\n",
    "print(f\"Average sampling time for RB: {avg_runtime_relbin / 3600} hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ratio of runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.654730445912453\n",
      "21.282421718641004\n",
      "23.430553669457105\n",
      "12.050676755854724\n"
     ]
    }
   ],
   "source": [
    "runtimes_ratio_float = {}\n",
    "runtimes_ratio_str = {}\n",
    "\n",
    "for key in jim_runtimes_float.keys():\n",
    "    ratio = bilby_runtimes_float[key] / jim_runtimes_float[key]\n",
    "    runtimes_ratio_float[key] = ratio\n",
    "    print(ratio)\n",
    "    runtimes_ratio_str[key] = f\"${int(ratio)} \\\\times $\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine into table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an older version, remove if not used anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex_code = '\\\\begin{{tabular}}{{l l c c c}}\\n Event & Waveform & \\\\texttt{{jim}} & \\\\texttt{{pbilby}} & Speed-up \\\\\\\\\\n \\hline\\\\hline\\n\\\\multirow{{2}}{{*}}{{GW170817}} & TF2 & {} & {} & {} \\\\\\\\\\n & NRTv2 & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{GW190425}}  & TF2 & {} & {} & {} \\\\\\\\ \\n & NRTv2 & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{Injection}} & TF2 & {} & -- & -- \\\\\\\\\\n& NRTv2 & {} & -- & -- \\\\\\\\\\n\\\\hline\\\\hline\\n\\\\end{{tabular}}'\\\n",
    "# .format(  jim_runtimes_str[\"GW170817_TaylorF2\"],\n",
    "#         bilby_runtimes_str[\"GW170817_TaylorF2\"],\n",
    "#         runtimes_ratio_str[\"GW170817_TaylorF2\"],\n",
    "#           jim_runtimes_str[\"GW170817_NRTidalv2\"],\n",
    "#         bilby_runtimes_str[\"GW170817_NRTidalv2\"], \n",
    "#         runtimes_ratio_str[\"GW170817_NRTidalv2\"],\n",
    "#           jim_runtimes_str[\"GW190425_TaylorF2\"], \n",
    "#         bilby_runtimes_str[\"GW190425_TaylorF2\"], \n",
    "#         runtimes_ratio_str[\"GW190425_TaylorF2\"],\n",
    "#           jim_runtimes_str[\"GW190425_NRTidalv2\"], \n",
    "#         bilby_runtimes_str[\"GW190425_NRTidalv2\"],\n",
    "#         runtimes_ratio_str[\"GW190425_NRTidalv2\"], \n",
    "#         jim_runtimes_injections_median_str[\"TF2\"], \n",
    "#         jim_runtimes_injections_median_str[\"NRTv2\"]\n",
    "#        )\n",
    "\n",
    "# print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environmental impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the GPU consumption, see [1] or [2]: we have 400W for a A100 GPU installed in SXM, which is the case for Snellius [3]. \n",
    "\n",
    "- For the CPUs used, look at Ref. [4].\n",
    "\n",
    "- Conversions to CO2 and trees: these are taken from Ref. [5]\n",
    "\n",
    "-  In short: \"For the capture of 1 tonne of CO2 emissions ~50 trees must grow for one year [6]\n",
    "^using 0.905 kg of CO2 per kilowatt hour [7].\"\n",
    "\n",
    "- For NL, the most recent value is 0.328 kg CO2 per kWh [8].\n",
    "\n",
    "[1] https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/PB-10577-001_v02.pdf\n",
    "\n",
    "[2] https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-nvidia-us-2188504-web.pdf \n",
    "\n",
    "[3] https://servicedesk.surf.nl/wiki/display/WIKI/Interactive+development+GPU+node \n",
    "\n",
    "[4] https://ark.intel.com/content/www/us/en/ark/products/136874/intel-xeon-platinum-8174-processor-33m-cache-3-10-ghz.html\n",
    "\n",
    "[5] https://git.ligo.org/lscsoft/parallel_bilby/-/wikis/O4-Review#pbilby-201-202 \n",
    "\n",
    "[6] https://www.climateneutralgroup.com/en/news/what-exactly-is-1-tonne-of-co2-v2/\n",
    "\n",
    "[7] https://www.dcceew.gov.au/climate-change/publications/national-greenhouse-gas-inventory-quarterly-updates\n",
    "\n",
    "[8] https://www.co2emissiefactoren.nl/lijst-emissiefactoren/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwh_to_co2 = 0.328 # kg CO2 per kWh\n",
    "co2_to_trees = (1 / 1000) * 50 # trees per kg CO2, growing for one year\n",
    "\n",
    "consumption_cpu_pbilby = 0.240 # kilowatts\n",
    "consumption_gpu = 0.400 # kilowatts\n",
    "\n",
    "N_gpu = 1\n",
    "N_runs = 204"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average runtime for jim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1488.1094314502734\n",
      "Average runtime jim (minutes): 24.801823857504555\n",
      "Average runtime jim (hours): 0.4133637309584092\n"
     ]
    }
   ],
   "source": [
    "total_runtime_events = np.sum(list(jim_runtimes_float.values()))\n",
    "avg_runtime_jim = (jim_total_runtime_injections + total_runtime_events) / N_runs # first in seconds\n",
    "print(avg_runtime_jim) # before: 1432.4360346029468\n",
    "\n",
    "# in minutes\n",
    "avg_runtime_jim /= 60\n",
    "print(f\"Average runtime jim (minutes):\", avg_runtime_jim) # before: 23.873933910049114\n",
    "\n",
    "# in hours\n",
    "avg_runtime_jim /= 60\n",
    "print(f\"Average runtime jim (hours):\", avg_runtime_jim) # before: 0.39789889850081855"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average runtime for bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average runtime bilby (hours): 8.42838576722222\n"
     ]
    }
   ],
   "source": [
    "avg_runtime_bilby = np.mean(list(bilby_runtimes_total.values())) / 3600\n",
    "print(\"Average runtime bilby (hours):\", avg_runtime_bilby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for GW170817_TaylorF2: 0.13 kWh\n",
      "Consumption for GW170817_NRTidalv2: 0.21 kWh\n",
      "Consumption for GW190425_TaylorF2: 0.14 kWh\n",
      "Consumption for GW190425_NRTidalv2: 0.16 kWh\n",
      "Consumption for avg: 0.17 kWh\n"
     ]
    }
   ],
   "source": [
    "consumption_jim = {}\n",
    "for key in jim_runtimes_float.keys():\n",
    "    consumption_jim[key] = N_gpu * consumption_gpu * (jim_runtimes_float[key] / 3600)\n",
    "    \n",
    "consumption_jim[\"avg\"] = N_gpu * consumption_gpu * avg_runtime_jim\n",
    "    \n",
    "for key, value in consumption_jim.items():\n",
    "    print(f\"Consumption for {key}: {value:.2f} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for GW170817_TaylorF2: 23.13 kWh\n",
      "Consumption for GW170817_NRTidalv2: 26.37 kWh\n",
      "Consumption for GW190425_TaylorF2: 19.62 kWh\n",
      "Consumption for GW190425_NRTidalv2: 11.79 kWh\n",
      "Consumption for avg: 20.23 kWh\n"
     ]
    }
   ],
   "source": [
    "N_cpu = 10\n",
    "\n",
    "consumption_bilby = {}\n",
    "for key in bilby_runtimes_float.keys():\n",
    "    consumption_bilby[key] = N_cpu * consumption_cpu_pbilby * (bilby_runtimes_float[key] / 3600)\n",
    "    \n",
    "consumption_bilby[\"avg\"] = N_cpu * consumption_cpu_pbilby * avg_runtime_bilby\n",
    "    \n",
    "for key, value in consumption_bilby.items():\n",
    "    print(f\"Consumption for {key}: {value:.2f} kWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for GW170817_TaylorF2: 172 x\n",
      "Consumption for GW170817_NRTidalv2: 128 x\n",
      "Consumption for GW190425_TaylorF2: 141 x\n",
      "Consumption for GW190425_NRTidalv2: 72 x\n",
      "Consumption for avg: 122 x\n"
     ]
    }
   ],
   "source": [
    "consumption_ratio = {}\n",
    "consumption_ratio_str = {}\n",
    "for key in consumption_jim.keys():\n",
    "    this_ratio = int(np.round(consumption_bilby[key] / consumption_jim[key]))\n",
    "    consumption_ratio[key] = this_ratio\n",
    "    consumption_ratio_str[key] = r\"${} \\times$\".format(this_ratio)\n",
    "    \n",
    "for key, value in consumption_ratio.items():\n",
    "    print(f\"Consumption for {key}: {value} x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to trees now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_killed_trees(kwh: float) -> float:\n",
    "    \"\"\"\n",
    "    Get the number of trees killed by the energy consumption of our runs in kWh.\n",
    "\n",
    "    Args:\n",
    "        kwh (float): Energy consumption in kWh\n",
    "\n",
    "    Returns:\n",
    "        float: Number of trees killed\n",
    "    \"\"\"\n",
    "    return kwh * kwh_to_co2 * co2_to_trees\n",
    "\n",
    "def get_number_of_tonne_co2(kwh: float) -> float:\n",
    "    \"\"\"\n",
    "    Get the number of trees killed by the energy consumption of our runs in kWh.\n",
    "\n",
    "    Args:\n",
    "        kwh (float): Energy consumption in kWh\n",
    "\n",
    "    Returns:\n",
    "        float: Number of trees killed\n",
    "    \"\"\"\n",
    "    return kwh * kwh_to_co2 / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees killed for GW170817_TaylorF2: 0.00221\n",
      "Trees killed for GW170817_NRTidalv2: 0.00339\n",
      "Trees killed for GW190425_TaylorF2: 0.00229\n",
      "Trees killed for GW190425_NRTidalv2: 0.00267\n",
      "Trees killed for avg: 0.00271\n"
     ]
    }
   ],
   "source": [
    "trees_jim = {}\n",
    "for key, value in consumption_jim.items():\n",
    "    trees_jim[key] = get_number_of_killed_trees(value)\n",
    "    \n",
    "for key, value in trees_jim.items():\n",
    "    print(f\"Trees killed for {key}: {value:.5f}\")\n",
    "    \n",
    "# Find the average:\n",
    "avg_nb_killed_trees_jim = np.mean(list(trees_jim.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees killed for GW170817_TaylorF2: 0.38\n",
      "Trees killed for GW170817_NRTidalv2: 0.43\n",
      "Trees killed for GW190425_TaylorF2: 0.32\n",
      "Trees killed for GW190425_NRTidalv2: 0.19\n",
      "Trees killed for avg: 0.33\n"
     ]
    }
   ],
   "source": [
    "trees_bilby = {}\n",
    "for key, value in consumption_bilby.items():\n",
    "    trees_bilby[key] = get_number_of_killed_trees(value)\n",
    "    \n",
    "for key, value in trees_bilby.items():\n",
    "    print(f\"Trees killed for {key}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a comparison **about the whole paper**, just use this average and the number of runs done to allow for an easier comparison between the 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of killed trees for writing the paper with   jim: 0.55\n",
      "Average number of killed trees for writing the paper with bilby: 67.68\n"
     ]
    }
   ],
   "source": [
    "# avg_nb_killed_trees_jim = np.mean(list(trees_jim.values()))\n",
    "# avg_nb_killed_trees_bilby = np.mean(list(trees_bilby.values()))\n",
    "\n",
    "avg_nb_killed_trees_jim = trees_jim[\"avg\"]\n",
    "avg_nb_killed_trees_bilby = trees_bilby[\"avg\"]\n",
    "\n",
    "avg_nb_killed_trees_jim_paper = N_runs * avg_nb_killed_trees_jim\n",
    "avg_nb_killed_trees_bilby_paper = N_runs * avg_nb_killed_trees_bilby\n",
    "\n",
    "print(f\"Average number of killed trees for writing the paper with   jim: {(avg_nb_killed_trees_jim_paper):.2f}\")\n",
    "print(f\"Average number of killed trees for writing the paper with bilby: {(avg_nb_killed_trees_bilby_paper):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonne CO2 for GW170817_TaylorF2: 0.00004\n",
      "Tonne CO2 for GW170817_NRTidalv2: 0.00007\n",
      "Tonne CO2 for GW190425_TaylorF2: 0.00005\n",
      "Tonne CO2 for GW190425_NRTidalv2: 0.00005\n",
      "Tonne CO2 for avg: 0.00005\n"
     ]
    }
   ],
   "source": [
    "co2_jim = {}\n",
    "for key, value in consumption_jim.items():\n",
    "    co2_jim[key] = get_number_of_tonne_co2(value)\n",
    "    \n",
    "for key, value in co2_jim.items():\n",
    "    print(f\"Tonne CO2 for {key}: {value:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonne CO2 for GW170817_TaylorF2: 0.00759\n",
      "Tonne CO2 for GW170817_NRTidalv2: 0.00865\n",
      "Tonne CO2 for GW190425_TaylorF2: 0.00644\n",
      "Tonne CO2 for GW190425_NRTidalv2: 0.00387\n",
      "Tonne CO2 for avg: 0.00663\n"
     ]
    }
   ],
   "source": [
    "co2_bilby = {}\n",
    "for key, value in consumption_bilby.items():\n",
    "    co2_bilby[key] = get_number_of_tonne_co2(value)\n",
    "    \n",
    "for key, value in co2_bilby.items():\n",
    "    print(f\"Tonne CO2 for {key}: {value:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROQ -- sampling time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for ROQ: 32.00 kWh\n",
      "CO2 for ROQ: 0.01049 tonnes\n",
      "Trees for ROQ: 0.52\n"
     ]
    }
   ],
   "source": [
    "# Runs used: Intel® Xeon® Gold 6136 Processor: https://www.intel.com/content/www/us/en/products/sku/215277/intel-xeon-silver-4310-processor-18m-cache-2-10-ghz/specifications.html\n",
    "N_cpu_roq = 1\n",
    "total_roq_runtime = N_runs * avg_runtime_roq\n",
    "consumption_cpu_roq_runtime = 0.120\n",
    "consumption_roq = N_cpu_roq * consumption_cpu_roq_runtime * (total_roq_runtime / 3600)\n",
    "\n",
    "# get co2 and trees\n",
    "co2_roq = get_number_of_tonne_co2(consumption_roq)\n",
    "trees_roq = get_number_of_killed_trees(consumption_roq)\n",
    "\n",
    "print(f\"Consumption for ROQ: {(consumption_roq):.2f} kWh\")\n",
    "print(f\"CO2 for ROQ: {co2_roq:.5f} tonnes\")\n",
    "print(f\"Trees for ROQ: {trees_roq:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROQ estimate, from building a single basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The number of bases is taken from the Morisaki et al 2023 paper (arXiv:2307.13380v1), Table II. Or from the [Gitlab wiki](https://git.ligo.org/pe/O4/review_bns_roq/-/wikis/Online%20and%20offline%20BNS%20ROQ%20bases) (needs LIGO credentials)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary function to estimate the time to run `params_to_basis.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_params_to_basis_runtimes(dir: str, verbose = True) -> float:\n",
    "#     \"\"\"\n",
    "#     Get the runtime of the params_to_basis script for the ROQ.\n",
    "\n",
    "#     Args:\n",
    "#         dir (str): Directory where the log files are stored. \n",
    "#         verbose (bool, optional): Give description of fetched values. Defaults to True.\n",
    "\n",
    "#     Returns:\n",
    "#         float: Runtime of params to basis, for all bases. \n",
    "#     \"\"\"\n",
    "    \n",
    "#     log_files = [f for f in os.listdir(dir) if f.endswith(\".log\")]\n",
    "#     runtime = 0\n",
    "    \n",
    "#     for filename in log_files:\n",
    "#         filename = dir + filename\n",
    "#         if verbose:\n",
    "#             print(f\" ---------- {filename} ----------\")\n",
    "#         with open(filename, 'r') as file:\n",
    "#             for line in file:\n",
    "#                 if \"Job executing on host\" in line:\n",
    "#                     start_time_str = line.split()[3]  # Extract the time part of the log entry\n",
    "#                     if verbose:\n",
    "#                         print(\"line\")\n",
    "#                         print(line)\n",
    "                    \n",
    "#                         print(\"start_time_str\")\n",
    "#                         print(start_time_str)\n",
    "#                     start_time = datetime.strptime(start_time_str, \"%H:%M:%S\").time()\n",
    "\n",
    "#                 elif \"Job terminated.\" in line:\n",
    "#                     end_time_str = line.split()[3]  # Extract the time part of the log entry\n",
    "#                     if verbose:\n",
    "#                         print(\"line\")\n",
    "#                         print(line)\n",
    "                        \n",
    "#                         print(\"end_time_str\")\n",
    "#                         print(end_time_str)\n",
    "                    \n",
    "#                     end_time = datetime.strptime(end_time_str, \"%H:%M:%S\").time()\n",
    "\n",
    "#         if start_time is None or end_time is None:\n",
    "#             return None  # Couldn't find both start and end times, return None\n",
    "\n",
    "#         # Calculate walltime\n",
    "#         start_datetime = datetime.combine(datetime.now().date(), start_time)\n",
    "#         end_datetime = datetime.combine(datetime.now().date(), end_time)\n",
    "#         walltime = end_datetime - start_datetime\n",
    "#         walltime_seconds = walltime.total_seconds()\n",
    "#         walltime_float = float(walltime_seconds)\n",
    "        \n",
    "#         if verbose:\n",
    "#             print(\"walltime:\")\n",
    "#             print(f\"{walltime_float}s = {walltime_float / 60} min = {walltime_float / 3600} h\")\n",
    "\n",
    "#         runtime += walltime_float\n",
    "    \n",
    "#     return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### BUILDING MODEL RUNTIME\n",
    "# consumption_cpu = 0.120\n",
    "\n",
    "# # Specify number of basis:\n",
    "# nb_linear_bases =  15 + 8 + 4 + 2\n",
    "# nb_quadratic_bases =  15 + 8 + 4 + 2\n",
    "\n",
    "# # Get the timing for a single basis, as timed by our run on LDAS CIT:\n",
    "# linear_basis_runtime = 4496 # seconds\n",
    "# quadratic_basis_runtime = 2699 # seconds: TODO: add once done here as well\n",
    "\n",
    "# # Multiply with number of bases (we are assuming here that this is more or less the same for various durations, which might be slightly inaccurate)\n",
    "# linear_basis_runtime *= nb_linear_bases\n",
    "# quadratic_basis_runtime *= nb_quadratic_bases\n",
    "\n",
    "# # Add both runtimes (linear and quadratic) together to get total runtime for training\n",
    "# total_basis_runtime = linear_basis_runtime + quadratic_basis_runtime\n",
    "# print(f\"The total runtime for building the bases was: {total_basis_runtime} s = {total_basis_runtime / 60} min = {total_basis_runtime / 3600} h\")\n",
    "\n",
    "# ### PARAMS TO BASIS RUNTIME\n",
    "# # Get the runtime from running the params to basis: \n",
    "# params_to_basis_logs_dir = \"/home/soichiro.morisaki/working/roq_pv2/final_basis/log/\"\n",
    "# runtime_params_to_basis = get_params_to_basis_runtimes(params_to_basis_logs_dir, verbose = False)\n",
    "\n",
    "# print(f\"The runtime of params to basis was: {runtime_params_to_basis} s = {runtime_params_to_basis / 60} min = {runtime_params_to_basis / 3600} h\")\n",
    "\n",
    "# # Add it to the total runtime\n",
    "# total_basis_runtime += runtime_params_to_basis\n",
    "# total_basis_runtime_hrs = total_basis_runtime / 3600\n",
    "# print(f\"Total runtime building a single ROQ basis: {total_basis_runtime_hrs} hrs\")\n",
    "\n",
    "# # Multiply by 2 to estimate the runtime for TaylorF2\n",
    "# total_basis_runtime *= 2\n",
    "\n",
    "# total_basis_runtime_hrs = total_basis_runtime / 3600\n",
    "# print(f\"Total runtime building 2 ROQ bases: {total_basis_runtime_hrs} hrs\")\n",
    "\n",
    "# print(\"--- Environmental impact --\")\n",
    "# consumption_roq_precompute = consumption_cpu * total_basis_runtime_hrs\n",
    "\n",
    "# co2_roq_precompute = get_number_of_tonne_co2(consumption_roq_precompute)\n",
    "# trees_roq_precompute = get_number_of_killed_trees(consumption_roq_precompute)\n",
    "# print(f\"Consumption for ROQ: {(consumption_roq_precompute):.2f} kWh\")\n",
    "# print(f\"CO2 for ROQ: {co2_roq_precompute:.5f} tonnes\")\n",
    "# print(f\"Trees for ROQ: {trees_roq_precompute:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks: did we do this correctly? NOT SURE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_basis_file = \"/home/thibeau.wouters/TurboPE-BNS/ROQ_build/out/linear.hdf5\"\n",
    "# with h5py.File(linear_basis_file) as f:\n",
    "#     print(f.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROQ -- construction time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an estimate of the basis size of the IMRPhenomPv2_NRTidalv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roq_basis_paths_Pv2_NRTv2 = \"/home/roq/IMRPhenomPv2_NRTidalv2/bns/\"\n",
    "\n",
    "# total_linear_basis_size_Pv2_NRTv2 = 0\n",
    "# total_quadratic_basis_size_Pv2_NRTv2 = 0\n",
    "\n",
    "# filenames = [\"basis_128s.hdf5\", \"basis_256s.hdf5\", \"basis_512s.hdf5\", \"basis_64s.hdf5\"]\n",
    "# for file in filenames:\n",
    "#     print(\"file\")\n",
    "#     print(file)\n",
    "#     with h5py.File(roq_basis_paths_Pv2_NRTv2 + file, \"r\") as f:\n",
    "#         print(f.keys())\n",
    "        \n",
    "#         # Fetch the linear bases\n",
    "#         linear_keys = f[\"basis_linear\"].keys()\n",
    "#         print(\"linear_keys\")\n",
    "#         print(linear_keys)\n",
    "        \n",
    "#         for key in linear_keys:\n",
    "#             print(np.shape(f[\"basis_linear\"][key]['basis'][()]))\n",
    "#             linear_basis_size = len(f[\"basis_linear\"][key]['basis'][()])\n",
    "#             total_linear_basis_size_Pv2_NRTv2 += linear_basis_size\n",
    "        \n",
    "#         # Fetch the quadratic bases\n",
    "#         quadratic_keys = f[\"basis_quadratic\"].keys()\n",
    "#         print(\"quadratic_keys\")\n",
    "#         print(quadratic_keys)\n",
    "#         for key in quadratic_keys:\n",
    "#             print(np.shape(f[\"basis_quadratic\"][key]['basis'][()]))\n",
    "#             quadratic_basis_size = len(f[\"basis_quadratic\"][key]['basis'][()])\n",
    "#             total_quadratic_basis_size_Pv2_NRTv2 += quadratic_basis_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(total_linear_basis_size_Pv2_NRTv2)\n",
    "# print(total_quadratic_basis_size_Pv2_NRTv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate from PyROQ paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO get an estimate here, wait for reply from the ROQ group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_cores = 40\n",
    "# consumption_cpu = 0.270 # CPU that can give 40 cores\n",
    "\n",
    "# # numbers averaged from their respective runs\n",
    "# linear_basis_size = 239\n",
    "# quadratic_basis_size = 176\n",
    "\n",
    "# hrs_linear = 53\n",
    "# hrs_quadratic = 51\n",
    "\n",
    "# cpu_hrs_per_basis_linear = N_cores * hrs_linear / linear_basis_size\n",
    "# cpu_hrs_per_basis_quadratic = N_cores * hrs_quadratic / quadratic_basis_size\n",
    "\n",
    "# total_cpu_hrs_linear = cpu_hrs_per_basis_linear * total_linear_basis_size_Pv2_NRTv2\n",
    "# total_cpu_hrs_quadratic = cpu_hrs_per_basis_quadratic * total_quadratic_basis_size_Pv2_NRTv2\n",
    "\n",
    "# print(f\"Total CPU hours for linear basis: {total_cpu_hrs_linear}\")\n",
    "# print(f\"Total CPU hours for quadratic basis: {total_cpu_hrs_quadratic}\")\n",
    "\n",
    "# total_cpu_hrs = total_cpu_hrs_linear + total_cpu_hrs_quadratic\n",
    "# total_cpu_hrs *= 2 # multiply by 2: also have to build the TaylorF2 basis\n",
    "\n",
    "# print(f\"Total CPU hours: {total_cpu_hrs}\")\n",
    "# consumption_roq_precompute = consumption_cpu * total_cpu_hrs / N_cores\n",
    "\n",
    "# co2_roq_precompute = get_number_of_tonne_co2(consumption_roq_precompute)\n",
    "# trees_roq_precompute = get_number_of_killed_trees(consumption_roq_precompute)\n",
    "# print(f\"Consumption for ROQ: {(consumption_roq_precompute):.2f} kWh\")\n",
    "# print(f\"CO2 for ROQ: {co2_roq_precompute:.5f} tonnes\")\n",
    "# print(f\"Trees for ROQ: {trees_roq_precompute:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute breakeven with Jim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Breakeven\n",
    "# difference = avg_nb_killed_trees_jim_paper - trees_roq\n",
    "# n_breakeven_runs = np.floor(trees_roq_precompute / difference)\n",
    "# print(f\"{n_breakeven_runs * N_runs} until break even between jim and ROQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROQ - construction time, estimated by Soichiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total CPU hours: 180.0\n",
      "Consumption for ROQ: 27.00 kWh\n",
      "CO2 for ROQ: 0.00886 tonnes\n",
      "Trees for ROQ: 0.44\n",
      "3060.0 until break even between jim and ROQ\n"
     ]
    }
   ],
   "source": [
    "# From email correspondence with Soichiro Morisaki:\n",
    "\n",
    "# Estimated time\n",
    "N_cpu = 5 # estimate\n",
    "total_cpu_hrs = 24 * N_cpu # hours\n",
    "total_cpu_hrs *= 1.5 # can multiply with certain number to estimate both bases\n",
    "\n",
    "consumption_cpu = 0.150 # not known\n",
    "\n",
    "print(f\"Total CPU hours: {total_cpu_hrs}\")\n",
    "consumption_roq_precompute = consumption_cpu * total_cpu_hrs\n",
    "\n",
    "co2_roq_precompute = get_number_of_tonne_co2(consumption_roq_precompute)\n",
    "trees_roq_precompute = get_number_of_killed_trees(consumption_roq_precompute)\n",
    "\n",
    "print(f\"Consumption for ROQ: {(consumption_roq_precompute):.2f} kWh\")\n",
    "print(f\"CO2 for ROQ: {co2_roq_precompute:.5f} tonnes\")\n",
    "print(f\"Trees for ROQ: {trees_roq_precompute:.2f}\")\n",
    "\n",
    "# Breakeven\n",
    "difference = avg_nb_killed_trees_jim_paper - trees_roq\n",
    "n_breakeven_runs = np.floor(trees_roq_precompute / difference)\n",
    "print(f\"{n_breakeven_runs * N_runs} until break even between jim and ROQ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relative binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for RB: 80.42 kWh\n",
      "CO2 for RB: 0.02638 tonnes\n",
      "Trees for RB: 1.32\n"
     ]
    }
   ],
   "source": [
    "N_cpu_relbin = 1\n",
    "total_relbin_time = N_runs * avg_runtime_relbin\n",
    "consumption_cpu_relbin = 0.120 # kilowatts\n",
    "\n",
    "# Get the numbers for the table\n",
    "consumption_relbin = N_cpu_relbin * consumption_cpu_relbin * (total_relbin_time / 3600)\n",
    "co2_relbin = get_number_of_tonne_co2(consumption_relbin)\n",
    "trees_relbin = get_number_of_killed_trees(consumption_relbin)\n",
    "\n",
    "print(f\"Consumption for RB: {consumption_relbin:.2f} kWh\")\n",
    "print(f\"CO2 for RB: {co2_relbin:.5f} tonnes\")\n",
    "print(f\"Trees for RB: {trees_relbin:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DINGO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an estimate. However, this is taken from the BBH paper and so therefore not worth mentioning since we consider BNS so it is not a great comparison..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consumption for Dingo for training: 96.00 kWh\n",
      "CO2 for Dingo for training: 0.03149 tonnes\n",
      "Trees for Dingo for training: 1.57\n",
      "=========================\n",
      "Consumption for Dingo for runs: 0.45 kWh\n",
      "CO2 for Dingo for runs: 0.00015 tonnes\n",
      "Trees for Dingo for runs: 0.01\n"
     ]
    }
   ],
   "source": [
    "N_gpu = 1\n",
    "dingo_training_time = 10 * 24 # hours\n",
    "\n",
    "### TRAINING\n",
    "consumption_dingo_training = N_gpu * consumption_gpu * dingo_training_time\n",
    "co2_dingo_training = get_number_of_tonne_co2(consumption_dingo_training)\n",
    "trees_dingo_training = get_number_of_killed_trees(consumption_dingo_training)\n",
    "\n",
    "print(f\"Consumption for Dingo for training: {consumption_dingo_training:.2f} kWh\")\n",
    "print(f\"CO2 for Dingo for training: {co2_dingo_training:.5f} tonnes\")\n",
    "print(f\"Trees for Dingo for training: {trees_dingo_training:.2f}\")\n",
    "\n",
    "### RUNTIME\n",
    "dingo_runtime = N_runs * 20 / 3600 # hours\n",
    "\n",
    "consumption_dingo_runtime = N_gpu * consumption_gpu * dingo_runtime\n",
    "co2_dingo_runtime = get_number_of_tonne_co2(consumption_dingo_runtime)\n",
    "trees_dingo_runtime = get_number_of_killed_trees(consumption_dingo_runtime)\n",
    "\n",
    "print(\"=========================\")\n",
    "\n",
    "print(f\"Consumption for Dingo for runs: {consumption_dingo_runtime:.2f} kWh\")\n",
    "print(f\"CO2 for Dingo for runs: {co2_dingo_runtime:.5f} tonnes\")\n",
    "print(f\"Trees for Dingo for runs: {trees_dingo_runtime:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get environmental impact as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex_code = '& kWh & $\\\\rm{{CO}}_2$ [$10^3$ kg] & Trees${{}}^\\dagger$ \\\\\\\\\\n \\hline\\\\hline\\n \\\\textsc{{Jim}} & $\\\\phantom{{00}}{}$ & $\\\\phantom{{0}}{}$ & $\\\\phantom{{000}}{}$ \\\\\\\\\\n \\\\textsc{{pBilby}} & ${}$ & ${}$ & ${}$ \\\\\\\\\\n \\\\textsc{{pBilby}} & ${}$ & ${}$ & ${}$ \\\\\\\\\\n \\\\textsc{{pBilby}} & ${}$ & ${}$ & ${}$ \\\\\\\\\\n\\\\hline\\\\hline'\\\n",
    "# .format(my_format(N_runs * consumption_jim[\"avg\"]),\n",
    "#         my_format(N_runs * co2_jim[\"avg\"]),\n",
    "#         my_format(avg_nb_killed_trees_jim_paper),\n",
    "#         my_format(N_runs * consumption_bilby[\"avg\"]),\n",
    "#         my_format(N_runs * co2_bilby[\"avg\"]),\n",
    "#         my_format(avg_nb_killed_trees_bilby_paper),\n",
    "#        )\n",
    "\n",
    "# print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122.0"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(avg_nb_killed_trees_bilby_paper / avg_nb_killed_trees_jim_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update the table with energy saved rather than speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latex_code = '\\\\begin{{tabular}}{{l l c c c}}\\n Event & Waveform & \\\\textsc{{Jim}} & \\\\textsc{{pBilby}} & Energy saved \\\\\\\\\\n \\hline\\\\hline\\n\\\\multirow{{2}}{{*}}{{GW170817}} & TF2 & {} & {} & {} \\\\\\\\\\n & NRTv2 & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{GW190425}}  & TF2 & {} & {} & {} \\\\\\\\ \\n & NRTv2 & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{Injection}} & TF2 & {} & -- & -- \\\\\\\\\\n& NRTv2 & {} & -- & -- \\\\\\\\\\n\\\\hline\\\\hline\\n\\\\end{{tabular}}'\\\n",
    "# .format(  jim_runtimes_str[\"GW170817_TaylorF2\"],\n",
    "#         bilby_runtimes_str[\"GW170817_TaylorF2\"],\n",
    "#          consumption_ratio_str[\"GW170817_TaylorF2\"],\n",
    "#          jim_runtimes_str[\"GW170817_NRTidalv2\"],\n",
    "#         bilby_runtimes_str[\"GW170817_NRTidalv2\"], \n",
    "#          consumption_ratio_str[\"GW170817_NRTidalv2\"],\n",
    "#            jim_runtimes_str[\"GW190425_TaylorF2\"], \n",
    "#         bilby_runtimes_str[\"GW190425_TaylorF2\"], \n",
    "#           consumption_ratio_str[\"GW190425_TaylorF2\"],\n",
    "#            jim_runtimes_str[\"GW190425_NRTidalv2\"], \n",
    "#         bilby_runtimes_str[\"GW190425_NRTidalv2\"],\n",
    "#          consumption_ratio_str[\"GW190425_NRTidalv2\"], \n",
    "#         jim_runtimes_injections[\"TF2\"], \n",
    "#         jim_runtimes_injections[\"NRTv2\"]\n",
    "#        )\n",
    "\n",
    "# print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without the final column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_entry_str_event(key):\n",
    "    return \"$(\" + jim_runtimes_str_evosax[key].replace(\"\\phantom{0}\", \"\") + \" + \" + jim_runtimes_str_sampling[key] + \")$ min\"\n",
    "\n",
    "def make_table_entry_str_injection(key):\n",
    "    return \"$\\phantom{{(0.000 + }} {}\\phantom{{)}}$ min\".format(np.round(jim_runtimes_injections_median[key], 2))\n",
    "\n",
    "def make_table_entry_str_RB(value, nb_round: int = 2):\n",
    "    return r\"${}$ h\".format(np.round(value / 3600, nb_round))\n",
    "\n",
    "def make_table_entry_str_ROQ(value, nb_round: int = 2):\n",
    "    return r\"${}$ h\".format(np.round(value / 3600, nb_round))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$\\\\phantom{(0.000 + } 24.76\\\\phantom{)}$ min'"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jim_runtimes_injections_median[\"TF2\"]\n",
    "make_table_entry_str_injection(\"TF2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 11/04/2024 -- added some runs with relative binninng and ROQ in Bilby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{l l c c c c}\n",
      " Event & WF & \\textsc{Jim} & \\textsc{pBilby} & RB -- \\textsc{Bilby} & ROQ -- \\textsc{Bilby}  \\\\\n",
      " & & \\footnotesize{($1$ GPU)} & \\footnotesize{($480$ cores)} & \\footnotesize{($24$ cores)} & \\footnotesize{($24$ cores)} \\\\\n",
      "  \\hline\\hline\n",
      " \\multirow{2}{*}{GW170817} & \\texttt{TF2} & $(4.85 + 15.33)$ min & $\\phantom{0}9.64$ h & $3.8$ h & -- \\\\\n",
      " & \\texttt{NRTv2} & $(5.38 + 25.59)$ min & $10.99$ h & $4.11$ h & $1.65$ h \\\\ \\hline\n",
      "\\multirow{2}{*}{GW190425}  & \\texttt{TF2} & $(2.63 + 18.30)$ min & $\\phantom{0}8.18$ h & $2.81$ h & -- \\\\ \n",
      " & \\texttt{NRTv2} & $(3.26 + 21.20)$ min & $\\phantom{0}4.91$ h & $2.42$ h & $0.97$ h \\\\ \\hline\n",
      "\\multirow{2}{*}{Injection} & \\texttt{TF2} & $\\phantom{(0.000 + } 24.76\\phantom{)}$ min & -- & -- & -- \\\\\n",
      "& \\texttt{NRTv2} & $\\phantom{(0.000 + } 18.02\\phantom{)}$ min & -- & -- & -- \\\\\n",
      "\\hline\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "latex_code = '\\\\begin{{tabular}}{{l l c c c c}}\\n Event & WF & \\\\textsc{{Jim}} & \\\\textsc{{pBilby}} & RB -- \\\\textsc{{Bilby}} & ROQ -- \\\\textsc{{Bilby}}  \\\\\\\\\\n & & \\\\footnotesize{{($1$ GPU)}} & \\\\footnotesize{{($480$ cores)}} & \\\\footnotesize{{($24$ cores)}} & \\\\footnotesize{{($24$ cores)}} \\\\\\\\\\n  \\hline\\\\hline\\n \\\\multirow{{2}}{{*}}{{GW170817}} & \\\\texttt{{TF2}} & {} & {} & {} & {} \\\\\\\\\\n & \\\\texttt{{NRTv2}} & {} & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{GW190425}}  & \\\\texttt{{TF2}} & {} & {} & {} & {} \\\\\\\\ \\n & \\\\texttt{{NRTv2}} & {} & {} & {} & {} \\\\\\\\ \\hline\\n\\\\multirow{{2}}{{*}}{{Injection}} & \\\\texttt{{TF2}} & {} & -- & -- & -- \\\\\\\\\\n& \\\\texttt{{NRTv2}} & {} & -- & -- & -- \\\\\\\\\\n\\\\hline\\\\hline\\n\\\\end{{tabular}}'\\\n",
    ".format(make_table_entry_str_event(\"GW170817_TaylorF2\"),\n",
    "        bilby_runtimes_str[\"GW170817_TaylorF2\"],\n",
    "        make_table_entry_str_RB(relbin_sampling_time_GW170817_TaylorF2),\n",
    "        \"--\",\n",
    "         make_table_entry_str_event(\"GW170817_NRTidalv2\"),\n",
    "        bilby_runtimes_str[\"GW170817_NRTidalv2\"], \n",
    "        make_table_entry_str_RB(relbin_sampling_time_GW170817_NRTidalv2),\n",
    "        make_table_entry_str_ROQ(roq_sampling_time_GW170817),\n",
    "         make_table_entry_str_event(\"GW190425_TaylorF2\"), \n",
    "        bilby_runtimes_str[\"GW190425_TaylorF2\"], \n",
    "        make_table_entry_str_RB(relbin_sampling_time_GW190425_TaylorF2),\n",
    "        \"--\",\n",
    "         make_table_entry_str_event(\"GW190425_NRTidalv2\"),\n",
    "        bilby_runtimes_str[\"GW190425_NRTidalv2\"],\n",
    "        make_table_entry_str_RB(relbin_sampling_time_GW190425_NRTidalv2),\n",
    "        make_table_entry_str_ROQ(roq_sampling_time_GW190425),\n",
    "        make_table_entry_str_injection(\"TF2\"), \n",
    "        make_table_entry_str_injection(\"NRTv2\"),\n",
    "       )\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_format(number: float, nb_round: int = 2):\n",
    "    rounded_value = np.round(number, nb_round)\n",
    "    if nb_round == 0:\n",
    "        rounded_value = int(rounded_value)\n",
    "    \n",
    "    my_string = str(rounded_value)\n",
    "    \n",
    "    if nb_round != 0:\n",
    "        before, after = my_string.split(\".\")\n",
    "        if len(after) == 1:\n",
    "            my_string = before + \".\" + after + \"0\"\n",
    "    return my_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& & kWh & $\\rm{CO}_2$ [$10^3$ kg] & Trees${}^\\dagger$ \\\\\n",
      " \\hline\\hline\n",
      " \\textsc{Jim} & & $\\phantom{00}34$ & $\\phantom{0}11$ & $\\phantom{000}0.55$ \\\\ \\hline \n",
      " \\textsc{pBilby} & & $4127$ & $1354$ & $67.68$ \\\\ \\hline \n",
      " \\textsc{\\textsc{RB-Bilby}} & & $80$ & $26$ & $1.32$ \\\\ \\hline \n",
      " \\multirow{2}{*}{\\textsc{ROQ-Bilby}} & sampling & $32$ & $10$ & $0.52$ \\\\ \n",
      " & precompute${}^\\ddagger$ & $27$ & $9$ & $0.44$ \\\\\n",
      "\\hline\\hline\n"
     ]
    }
   ],
   "source": [
    "nb_round_kwh = 0\n",
    "nb_round_co2 = 0\n",
    "\n",
    "co2_factor = 1000\n",
    "latex_code = '& & kWh & $\\\\rm{{CO}}_2$ [$10^3$ kg] & Trees${{}}^\\dagger$ \\\\\\\\\\n \\hline\\\\hline\\n \\\\textsc{{Jim}} & & $\\\\phantom{{00}}{}$ & $\\\\phantom{{0}}{}$ & $\\\\phantom{{000}}{}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{pBilby}} & & ${}$ & ${}$ & ${}$ \\\\\\\\ \\\\hline \\n \\\\textsc{{\\\\textsc{{RB-Bilby}}}} & & ${}$ & ${}$ & ${}$ \\\\\\\\ \\\\hline \\n \\\\multirow{{2}}{{*}}{{\\\\textsc{{ROQ-Bilby}}}} & sampling & ${}$ & ${}$ & ${}$ \\\\\\\\ \\n & precompute${{}}^\\ddagger$ & ${}$ & ${}$ & ${}$ \\\\\\\\\\n\\\\hline\\\\hline'\\\n",
    ".format(my_format(N_runs * consumption_jim[\"avg\"], nb_round_kwh), # jim\n",
    "        my_format(N_runs * co2_jim[\"avg\"] * co2_factor, nb_round = nb_round_co2),\n",
    "        my_format(avg_nb_killed_trees_jim_paper),\n",
    "        my_format(N_runs * consumption_bilby[\"avg\"], nb_round_kwh), # pBilby\n",
    "        my_format(N_runs * co2_bilby[\"avg\"]  * co2_factor, nb_round = nb_round_co2),\n",
    "        my_format(avg_nb_killed_trees_bilby_paper),\n",
    "        my_format(consumption_relbin, nb_round_kwh), # RB-Bilby\n",
    "        my_format(co2_relbin  * co2_factor, nb_round = nb_round_co2),\n",
    "        my_format(trees_relbin),\n",
    "        my_format(consumption_roq, nb_round_kwh), # ROQ-Bilby, sampling time\n",
    "        my_format(co2_roq  * co2_factor, nb_round = nb_round_co2),\n",
    "        my_format(trees_roq),\n",
    "        my_format(consumption_roq_precompute, nb_round_kwh),# ROQ-Bilby, constructing base time\n",
    "        my_format(co2_roq_precompute * co2_factor, nb_round = nb_round_co2),\n",
    "        my_format(trees_roq_precompute),\n",
    "       )\n",
    "\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3060"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(N_runs * n_breakeven_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
